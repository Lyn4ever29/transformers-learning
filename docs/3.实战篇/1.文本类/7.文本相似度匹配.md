## 问题
1. 计算两个文本之间的相似度，相似返回1，不相似返回0
2. 从n个候选文本中选取出与当前文本最相似的文本
## 解决方案

### 问题1
- 问题：计算两个文本之是否相似，相似返回1，不相似返回0
- 数据集：[shibing624/sts-sohu2021](https://huggingface.co/datasets/shibing624/sts-sohu2021)2021搜狐校园文本匹配算法大赛数据集，数据来源[https://www.biendata.xyz/competition/sohu_2021/data/](https://www.biendata.xyz/competition/sohu_2021/data/),由于计算资源有限，只选择其中短短文本匹配作为样例。
- 模型：哈工大的一个中文BERT，下载地址[hfl/chinese-macbert-base](https://huggingface.co/hfl/chinese-macbert-base)
- 代码实现：
<details> 
<summary>展开查看问题1代码</summary> 
1.  数据预处理
```python
datas = load_dataset("shibing624/sts-sohu2021",'dda')
tokenizer = AutoTokenizer.from_pretrained("hfl/chinese-macbert-base")
def process_fun(examples):
	tokenized_examples=tokenizer(
							 examples['sentence1']，examples['sentence2'],
							 padding=True,max_length=64,return_tensors='pt')
    tokenized_examples["labels"] = [label for label in examples["label"]]
    return tokenized_examples
data_tokenizer = datas.map(process_fun,batched=True,remove_columns=datas["train"].column_names)
```

2. 加载模型
注意指定num_labels来说明这是一个二分类问题
```python
model = AutoModelForSequenceClassification.from_pretrained("hfl/chinese-macbert-base", num_labels=2)
```
3. 创建评估函数
```python
import evaluate
acc_metric = evaluate.load("accuracy")
f1_metirc = evaluate.load("f1")
def eval_metric(eval_predict):
    predictions, labels = eval_predict
    predictions = predictions.argmax(axis=-1)
    acc = acc_metric.compute(predictions=predictions, references=labels)
    f1 = f1_metirc.compute(predictions=predictions, references=labels,average='macro')
    acc.update(f1)
    return acc
```
4. 设置训练参数
```python
train_args = TrainingArguments(
	output_dir="./similarity_model",      # 输出文件夹
	per_device_train_batch_size=32,  # 训练时的batch_size
	per_device_eval_batch_size=32,  # 验证时的batch_size
	logging_steps=10,                # log 打印的频率
	evaluation_strategy="epoch",     # 评估策略
	save_strategy="epoch",           # 保存策略
	save_total_limit=3,              # 最大保存数
	learning_rate=2e-5,              # 学习率
	weight_decay=0.01,               # weight_decay
	metric_for_best_model="f1",      # 设定评估指标
	load_best_model_at_end=True)     # 训练完成后加载最优模型
```
5. 定义训练器
```python 
trainer = Trainer(model=model,
                  args=train_args,
                  train_dataset=data_tokenizer["train"],
                  eval_dataset=data_tokenizer["test"],
                  data_collator=DataCollatorWithPadding(tokenizer=tokenizer),
                  compute_metrics=eval_metric)
```
6. 训练
```python
trainer.train()
```
7. 评估
```python
eval_result = trainer.evaluate(data_tokenizer["test"])
eval_result
```
结果如下：
```json
{'eval_loss': 0.36066102981567383,
 'eval_accuracy': 0.837,
 'eval_f1': 0.8010678871090771,
 'eval_runtime': 9.8404,
 'eval_samples_per_second': 101.622,
 'eval_steps_per_second': 3.252,
 'epoch': 3.0}
```
8. 推理
```python
from transformers import pipeline, TextClassificationPipeline
model.config.id2label = {0: "不相似", 1: "相似"}
pipe = pipeline('text-classification', model=model, tokenizer=tokenizer,device=0)
result = pipe({"text": "我喜欢北京", "text_pair": "北京是个好地方"}, function_to_apply="none")
result
```
结果如下：
```json
{'label': '相似', 'score': 0.049160078167915344}
```
</details>


### 问题2
- 问题：从n个候选文本中选取出与当前文本最相似的文本
- 思路：大体思路与问题1 相似，但是如果直接用问题1的办法，则需要两两对比，时间复杂度是O(n^2)，效率太低了。所以解决思路为训练一个计算两个文本相似度分类的编码模型，然后将所有的候选文本利用这个编码模型进行编码存起来，然后就可以利用向量数据库进行查询，参考[9.基于向量匹配的检索式问答实战](9.基于向量匹配的检索式问答实战.md)
- 数据集：[shibing624/sts-sohu2021](https://huggingface.co/datasets/shibing624/sts-sohu2021)2021搜狐校园文本匹配算法大赛数据集，数据来源[https://www.biendata.xyz/competition/sohu_2021/data/](https://www.biendata.xyz/competition/sohu_2021/data/),由于计算资源有限，只选择其中短短文本匹配作为样例。
- 模型：哈工大的一个中文BERT，下载地址[hfl/chinese-macbert-base](https://huggingface.co/hfl/chinese-macbert-base)
- 代码实现：
<details>
<summary>展开查看问题2代码</summary>
</details>
