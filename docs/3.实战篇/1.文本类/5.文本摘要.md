## 任务描述
文本摘要是指通过各种技术，对文本或者是文本的集合，抽取、总结或是精炼其中的要点信息，用以概括和展示原始文本的主要内容或大意。作为文本生成任务的主要方向之一，从本质上而言，这是一种信息压缩技术。文本摘要技术是信息爆炸时代，提升人们获取有效信息效率的关键技术之一，如何从冗余、非结构化的长文本中提炼出关键信息，构成精简通顺的摘要，是文本摘要的核心问题。
## 实验概述
在之前的文章[6.预训练模型实战](6.预训练模型实战.md)中，介绍到了四种预训练语言模型，四种语言模型都可以做文本摘要任务，但像bert这种掩码语言模型效果就相对差一点儿。本文选取四种语言模型，在文本摘要任务上做对比试验。
## 实验配置
### 数据集
[LCSTS_new中文短摘要生成数据集](https://www.luge.ai/#/luge/dataDetail?id=10)
2015年发布的生成式短摘要数据集，以微博原文为输入，1~2句话的短摘要为输出。
#### 预训练模型
> 鉴于资源限制，本文选择的模型在一方面要支持中文，另一方面要模型体积尽可能小，所以本实验的结果并不能代表模型的性能。
1. [hfl/chinese-macbert-base](https://huggingface.co/hfl/chinese-macbert-base)
	掩码语言模型
2. [Langboat/mengzi-t5-base](https://huggingface.co/Langboat/mengzi-t5-base)
	seq2seq模型
3. [uer/gpt2-chinese-cluecorpussmall](https://huggingface.co/uer/gpt2-chinese-cluecorpussmall/tree/main)
	因果语言模型，为什么不直接选择GPT-2？是因为官方的GPT-2并不支持中文。
4. [THUDM/glm-large-chinese](https://huggingface.co/THUDM/glm-large-chinese)
	前缀语言模型
### 评价标注
Rouge-Chinese库 （Python）
- 专用于计算中文rouge指标的[python库](https://so.csdn.net/so/search?q=python%E5%BA%93&spm=1001.2101.3001.7020) [(paper)](http://www.aclweb.org/anthology/W04-1013)
- 完整代码请见github仓库：[https://github.com/Isaac-JL-Chen/rouge_chinese](https://github.com/Isaac-JL-Chen/rouge_chinese)
- 安装方法:
```shell
pip install rouge-chinese
```
- 使用方法
```python
from rouge_chinese import Rouge

true_data=['张三是个好学生',
		   '小鱼吃猫博客是个好网站',
		   '小鱼不吃香菜']
pred_data=['张三是个坏学生',
		   '小鱼吃猫博客确实是个好网站',
		   '小鱼不吃香菜，所以长不高']
true_list=[' '.join(true_data) for arg in dev_data]
pred_list=[' '.join(pred_data) for arg in dev_data]
rouge = Rouge()
scores = rouge.get_scores(pred_list, true_list, avg=True)
{
    "rouge-1": scores["rouge-1"]["f"],
    "rouge-2": scores["rouge-2"]["f"],
    "rouge-l": scores["rouge-l"]["f"],
}
```
## 代码实现
[5.1.文本摘要之前缀语言模型-GLM](5.1.文本摘要之前缀语言模型-GLM.md)
[5.2.文本摘要之序列到序列模型-t5](5.2.文本摘要之序列到序列模型-t5.md)


